{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0       name pos  year\n",
      "0           0   john doe  1B  2000\n",
      "1           1   al smith   C  2004\n",
      "2           2  sam black   P  2008\n",
      "3           3   john doe  2B  2003\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlb_df1 = pd.DataFrame({'name': ['john doe', 'al smith', 'sam black', 'john doe'],\n",
    "                        'pos': ['1B', 'C', 'P', '2B'],\n",
    "                        'year': [2000, 2004, 2008, 2003]})\n",
    "\n",
    "mlb_df1.to_csv(\"CSVdata.csv\") # this line makes a new .csv file and also add the data (mlb_df1) to it \n",
    "existing_data = pd.read_csv(\"CSVdata.csv\") # now the data of this .csv file comes into existing_data\n",
    "print('{}\\n'.format(existing_data)) # it prints the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Reading data\n",
    "One of the most important features in pandas is the ability to read from data files. pandas accepts a variety of file formats, ranging from CSV and Excel spreadsheets to SQL and even HTML. A full list of the available file formats for pandas can be found here.\n",
    "\n",
    "In this chapter we'll focus on three of the most common file types: CSV, XLSX (Microsoft Excel), and JSON. For reading data from a file, we use either the read_csv, read_excel, or read_json function, depending on the file type.\n",
    "\n",
    "Each of the file reading functions takes in a file path as the only required argument. Each function has numerous keyword arguments, so we won't get into most of them. However, we'll still discuss a couple of the more commonly used keyword arguments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV\n",
    "A CSV file is pretty straightforward; it's just comma-separated column names and values. When we don't use any keyword arguments, pd.read_csv returns a DataFrame with integer indexes as row labels, and each comma-separated column name as the column labels.\n",
    "\n",
    "However, when we set the index_col keyword argument, we specify which column we want to use as the row labels. In our example, we used the first and second column as row labels.\n",
    "\n",
    "The code below shows how to use pd.read_csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0       name pos  year\n",
      "0           0   john doe  1B  2000\n",
      "1           1   al smith   C  2004\n",
      "2           2  sam black   P  2008\n",
      "3           3   john doe  2B  2003\n",
      "\n",
      "        name pos  year\n",
      "0   john doe  1B  2000\n",
      "1   al smith   C  2004\n",
      "2  sam black   P  2008\n",
      "3   john doe  2B  2003\n",
      "\n",
      "           Unnamed: 0 pos  year\n",
      "name                           \n",
      "john doe            0  1B  2000\n",
      "al smith            1   C  2004\n",
      "sam black           2   P  2008\n",
      "john doe            3  2B  2003\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# data.csv contains baseball data\n",
    "df = pd.read_csv('CSVdata.csv')\n",
    "# Newline to separate print statements\n",
    "print('{}\\n'.format(df))\n",
    "\n",
    "df = pd.read_csv('CSVdata.csv', index_col=0) # it uses first column as a row label\n",
    "print('{}\\n'.format(df))\n",
    "\n",
    "df = pd.read_csv('CSVdata.csv', index_col=1) # it uses second column as a row label\n",
    "print('{}\\n'.format(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write Exel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        name pos  year\n",
      "0   john doe  1B  2000\n",
      "1   al smith   C  2004\n",
      "2  sam black   P  2008\n",
      "3   john doe  2B  2003\n"
     ]
    }
   ],
   "source": [
    "exel_data = pd.DataFrame({'name': ['john doe', 'al smith', 'sam black', 'john doe'],\n",
    "                        'pos': ['1B', 'C', 'P', '2B'],\n",
    "                        'year': [2000, 2004, 2008, 2003]})\n",
    "\n",
    "# making an excel file\n",
    "exel_data.to_excel('EXCELdata.xlsx', index = False) # by writing index = False it don't print extra index\n",
    "\n",
    "dataOfExcelFile = pd.read_excel('EXCELdata.xlsx')\n",
    "print(dataOfExcelFile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An Excel spreadsheet is similar to a CSV in its usage of rows and columns. However, the file path for pd.read_excel normally specifies an Excel workbook, which can contain multiple spreadsheets.\n",
    "\n",
    "When we don't use any keyword arguments, the returned DataFrame from pd.read_excel contains the first sheet of the Excel workbook. However, when we set the sheet_name keyword argument, we can obtain a specific spreadsheet by passing in its integer index or name.\n",
    "\n",
    "Furthermore, we obtain an ordered dictionary of spreadsheets by passing in a list of integers or sheet names. Setting sheet_name=None returns all the sheets in an ordered dictionary.\n",
    "\n",
    "Like pd.read_csv, we can also specify the index_col argument in pd.read_excel.\n",
    "\n",
    "The code below shows how to use pd.read_excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        name pos  year\n",
      "0   john doe  1B  2000\n",
      "1   al smith   C  2004\n",
      "2  sam black   P  2008\n",
      "3   john doe  2B  2003\n",
      "\n",
      "dict_keys(['Sheet1'])\n"
     ]
    }
   ],
   "source": [
    "# data.csv contains baseball data\n",
    "df = pd.read_excel('EXCELdata.xlsx') # by default it takes first sheet of excel workbook\n",
    "# Newline to separate print statements\n",
    "print('{}\\n'.format(df))\n",
    "\n",
    "# print('Sheet 1 (0-indexed) DataFrame:')\n",
    "# df = pd.read_excel('EXCELdata.xlsx', sheet_name=1) # it shows error because we are trying to access second sheet of excel workbook which is not present or made by us\n",
    "# print('{}\\n'.format(df))\n",
    "\n",
    "# print('MIL DataFrame:')\n",
    "# df = pd.read_excel('EXCELdata.xlsx', sheet_name='MIL') # it also shows error because we are trying to access MIL named sheet which is not made by us in this file\n",
    "# print('{}\\n'.format(df))\n",
    "\n",
    "# # Sheets 0 and 1\n",
    "# df_dict = pd.read_excel('EXCELdata.xlsx', sheet_name=[0, 1]) # it also shows error because we are trying to access a ranged sheets and we have only one in our file\n",
    "# print('{}\\n'.format(df_dict[1]))\n",
    "\n",
    "# All Sheets\n",
    "df_dict = pd.read_excel('EXCELdata.xlsx', sheet_name=None) # by setting it to None we get all the available sheets in a dictionary form\n",
    "print(df_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       name  age      city    hobbies\n",
      "0  John Doe   30  New York    reading\n",
      "1  John Doe   30  New York  traveling\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Sample data\n",
    "data = {\"name\": \"John Doe\",\n",
    "        \"age\": 30,\n",
    "        \"city\": \"New York\",\n",
    "        \"hobbies\": [\"reading\", \"traveling\"]}\n",
    "\n",
    "# Specify the file path\n",
    "json_file_path = 'JSONdata.json'\n",
    "\n",
    "# Write data to JSON file\n",
    "with open(json_file_path, 'w') as json_file:\n",
    "    json.dump(data, json_file, indent = 2) # 'indent' parameter is optional for pretty formatting\n",
    "\n",
    "data = pd.read_json('JSONdata.json')\n",
    "print('{}\\n'.format(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JSON\n",
    "JSON data is pretty similar to a Python dictionary. In fact, you can use the json module (part of the Python standard library) to convert between dictionaries and JSON data. The file path for pd.read_json specifies a file containing JSON data.\n",
    "\n",
    "When we don't use any keyword arguments, pd.read_json treats each outer key of the JSON data as a column label and each inner key as a row label. In the code example below, you can see df1 treats the player's names as column labels.\n",
    "\n",
    "However, when we set orient='index', the outer keys are treated as row labels and the inner keys are treated as column labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       name  age      city    hobbies\n",
      "0  John Doe   30  New York    reading\n",
      "1  John Doe   30  New York  traveling\n",
      "\n",
      "       name  age      city    hobbies\n",
      "0  John Doe   30  New York    reading\n",
      "1  John Doe   30  New York  traveling\n",
      "\n",
      "                            0\n",
      "name                 John Doe\n",
      "age                        30\n",
      "city                 New York\n",
      "hobbies  [reading, traveling]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# data is the JSON data (as a Python dict)\n",
    "print('{}\\n'.format(data))\n",
    "\n",
    "df1 = pd.read_json('JSONdata.json') # this prints according to that label whose number of attributes is high and in our case it is hobbies\n",
    "print('{}\\n'.format(df1))\n",
    "\n",
    "df2 = pd.read_json('JSONdata.json', orient='index') # this method is more suitable to write in our case because it prints as input is given\n",
    "print('{}\\n'.format(df2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Writing to files\n",
    "We can also use pandas to write data to a file. Focusing again on CSV, Excel, and JSON, the functions we use to write to files are to_csv, to_excel, and to_json.\n",
    "\n",
    "Similar to the file reading functions, each of the writing functions has dozens of keyword arguments. Therefore, we'll only go over a few of the commonly used ones.\n",
    "\n",
    "# CSV\n",
    "Note that when we don't use any keyword arguments, to_csv will write the row labels as the first column in the CSV file. This is fine if the row labels are meaningful, but if they are just integers we don't really want them in the CSV file. In that case, we set index=False, to specify that we don't write the row labels into the CSV file.\n",
    "\n",
    "The code below shows how to use to_csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       name  age      city    hobbies\n",
      "0  John Doe   30  New York    reading\n",
      "1  John Doe   30  New York  traveling\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Sample data\n",
    "data = {\"name\": \"John Doe\",\n",
    "        \"age\": 30,\n",
    "        \"city\": \"New York\",\n",
    "        \"hobbies\": [\"reading\", \"traveling\"]}\n",
    "\n",
    "# Specify the file path\n",
    "json_file_path = 'JSONdata.json'\n",
    "\n",
    "# Write data to JSON file\n",
    "with open(json_file_path, 'w') as json_file:\n",
    "    json.dump(data, json_file, indent = 2) # 'indent' parameter is optional for pretty formatting\n",
    "\n",
    "data = pd.read_json('JSONdata.json')\n",
    "print('{}\\n'.format(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       name  year  rbi\n",
      "0  john doe  2000   80\n",
      "1  al smith  2004  100\n",
      "2  jack lee  2012   12\n",
      "\n",
      "   Unnamed: 0      name  year  rbi\n",
      "0           0  john doe  2000   80\n",
      "1           1  al smith  2004  100\n",
      "2           2  jack lee  2012   12\n",
      "\n",
      "       name  year  rbi\n",
      "0  john doe  2000   80\n",
      "1  al smith  2004  100\n",
      "2  jack lee  2012   12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlb_df2 = pd.DataFrame({'name': ['john doe', 'al smith', 'jack lee'],\n",
    "                        'year': [2000, 2004, 2012],\n",
    "                        'rbi': [80, 100, 12]})\n",
    "# Predefined mlb_df\n",
    "print('{}\\n'.format(mlb_df2))\n",
    "\n",
    "# Index is kept when writing\n",
    "mlb_df2.to_csv('CSVdata.csv')\n",
    "df = pd.read_csv('CSVdata.csv')\n",
    "print('{}\\n'.format(df))\n",
    "\n",
    "# Index is not kept when writing\n",
    "mlb_df2.to_csv('CSVdata.csv', index=False)\n",
    "df = pd.read_csv('CSVdata.csv')\n",
    "print('{}\\n'.format(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excel\n",
    "The basic to_excel function will only write a single DataFrame to a spreadsheet. However, if we want to write multiple spreadsheets in an Excel workbook, we first load the Excel file into a pd.ExcelWriter then use the ExcelWriter as the first argument to to_excel.\n",
    "\n",
    "When we don't specify the sheet_name keyword argument, the Excel spreadsheet we write to is named 'Sheet1'. We can pass in custom names into sheet_name to avoid constantly writing to 'Sheet1'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        name pos  year\n",
      "0   john doe  1B  2000\n",
      "1   al smith   C  2004\n",
      "2  sam black   P  2008\n",
      "3   john doe  2B  2003\n",
      "\n",
      "       name  year  rbi\n",
      "0  john doe  2000   80\n",
      "1  al smith  2004  100\n",
      "2  jack lee  2012   12\n",
      "\n",
      "dict_keys(['NYY', 'BOS'])\n",
      "\n",
      "       name  year  rbi\n",
      "0  john doe  2000   80\n",
      "1  al smith  2004  100\n",
      "2  jack lee  2012   12\n",
      "\n",
      "        name pos  year\n",
      "0   john doe  1B  2000\n",
      "1   al smith   C  2004\n",
      "2  sam black   P  2008\n",
      "3   john doe  2B  2003\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predefined DataFrames\n",
    "print('{}\\n'.format(mlb_df1))\n",
    "print('{}\\n'.format(mlb_df2))\n",
    "\n",
    "with pd.ExcelWriter('EXCELdata.xlsx') as writer:\n",
    "  mlb_df1.to_excel(writer, index=False, sheet_name='NYY')\n",
    "  mlb_df2.to_excel(writer, index=False, sheet_name='BOS')\n",
    "  \n",
    "df_dict = pd.read_excel('EXCELdata.xlsx', sheet_name=None)\n",
    "print('{}\\n'.format(df_dict.keys()))\n",
    "print('{}\\n'.format(df_dict['BOS']))\n",
    "print('{}\\n'.format(df_dict['NYY']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JSON\n",
    "The to_json function also uses the orient keyword argument that was part of pd.read_json. Like in pd.read_json, setting orient='index' will set the outer keys of the JSON data to the row labels and the inner keys to the column labels.\n",
    "\n",
    "The code below shows how to use to_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       name  year  rbi\n",
      "0  john doe  2000   80\n",
      "1  al smith  2004  100\n",
      "2  jack lee  2012   12\n",
      "\n",
      "       name  year  rbi\n",
      "0  john doe  2000   80\n",
      "1  al smith  2004  100\n",
      "2  jack lee  2012   12\n",
      "\n",
      "             0         1         2\n",
      "name  john doe  al smith  jack lee\n",
      "year      2000      2004      2012\n",
      "rbi         80       100        12\n",
      "\n",
      "       name  year  rbi\n",
      "0  john doe  2000   80\n",
      "1  al smith  2004  100\n",
      "2  jack lee  2012   12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predefined df\n",
    "print('{}\\n'.format(df))\n",
    "\n",
    "df.to_json('JSONdata.json')\n",
    "df2 = pd.read_json('JSONdata.json')\n",
    "print('{}\\n'.format(df2))\n",
    "\n",
    "df.to_json('JSONdata.json', orient='index')\n",
    "df2 = pd.read_json('JSONdata.json')\n",
    "print('{}\\n'.format(df2))\n",
    "df2 = pd.read_json('JSONdata.json', orient='index')\n",
    "print('{}\\n'.format(df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
