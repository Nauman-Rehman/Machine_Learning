{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Data outliers\n",
    "An important aspect of data that we have to deal with is outliers. In general terms, an outlier is a data point that is significantly further away from the other data points. For example, if we had watermelons of weights 5, 4, 6, 7, and 20 pounds, the 20 pound watermelon is an outlier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data scaling methods from the previous two chapters are both affected by outliers. Data standardization uses each feature's mean and standard deviation, while ranged scaling uses the maximum and minimum feature values, meaning that they're both susceptible to being skewed by outlier values.\n",
    "\n",
    "We can robustly scale the data, i.e. avoid being affected by outliers, by using use the data's median and Interquartile Range (IQR). Since the median and IQR are percentile measurements of the data (50% for median, 25% to 75% for the IQR), they are not affected by outliers. For the scaling method, we just subtract the median from each data value then scale to the IQR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Robust scaling with scikit-learn\n",
    "In scikit-learn, we perform robust scaling with the RobustScaler module. It is another transformer object, with the same fit, transform, and fit_transform functions described in the previous chapter.\n",
    "\n",
    "The code below shows how to use the RobustScaler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Robust scaling is a method of scaling features in a dataset, similar to other scaling techniques like standardization or normalization. The goal of robust scaling is to center and scale the features, making them suitable for certain machine learning algorithms or statistical analyses.\n",
    "\n",
    "The robust scaling process involves the following steps:\n",
    "\n",
    "Centering (Median Centering): Subtract the median from each feature. This is done to center the data around the median instead of the mean, making it less sensitive to the influence of outliers.\n",
    "\n",
    "Scaling (Interquartile Range Scaling): Divide each feature by the interquartile range (IQR), which is the range between the first quartile (25th percentile) and the third quartile (75th percentile). This scaling method is less influenced by extreme values (outliers) compared to standardization or normalization.\n",
    "\n",
    "The formula for robust scaling for a single feature X is given by\n",
    "\n",
    "## &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; X<sub>robust scaled</sub> = (X - median(X)) / IQR(X)\n",
    "##### Here, median(X) is the median of a feature(X), and IQR(X) is the interquartile range of X.\n",
    "\n",
    "Robust scaling is particularly useful when dealing with datasets that contain outliers, as it reduces the impact of extreme values on the scaling process. It's commonly used in situations where the distribution of features may not be normal or when the presence of outliers can significantly affect the performance of a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[ 1.2,  2.3],\n",
      "       [ 2.1,  4.2],\n",
      "       [-1.9,  3.1],\n",
      "       [-2.5,  2.5],\n",
      "       [ 0.8,  3. ],\n",
      "       [ 6.3,  2.1],\n",
      "       [-1.5,  2.7],\n",
      "       [ 1.4,  2.9],\n",
      "       [ 1.8,  3.2]])\n",
      "\n",
      "array([[ 0.        , -1.        ],\n",
      "       [ 0.27272727,  2.16666667],\n",
      "       [-0.93939394,  0.33333333],\n",
      "       [-1.12121212, -0.66666667],\n",
      "       [-0.12121212,  0.16666667],\n",
      "       [ 1.54545455, -1.33333333],\n",
      "       [-0.81818182, -0.33333333],\n",
      "       [ 0.06060606,  0.        ],\n",
      "       [ 0.18181818,  0.5       ]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = np.array([[ 1.2,  2.3],\n",
    "                 [ 2.1,  4.2],\n",
    "                 [-1.9,  3.1],\n",
    "                 [-2.5,  2.5],\n",
    "                 [ 0.8,  3. ],\n",
    "                 [ 6.3,  2.1],\n",
    "                 [-1.5,  2.7],\n",
    "                 [ 1.4,  2.9],\n",
    "                 [ 1.8,  3.2]])\n",
    "\n",
    "print('{}\\n'.format(repr(data)))\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "robust_scaler = RobustScaler()\n",
    "transformed = robust_scaler.fit_transform(data)\n",
    "print('{}\\n'.format(repr(transformed)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
