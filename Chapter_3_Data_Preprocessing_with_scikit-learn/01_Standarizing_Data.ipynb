{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Standard data format\n",
    "Data can contain all sorts of different values. For example, Olympic 100m sprint times will range from 9.5 to 10.5 seconds, while calorie counts in large pepperoni pizzas can range from 1500 to 3000 calories. Even data measuring the exact same quantities can range in value (e.g. weight in kilograms vs. weight in pounds).\n",
    "\n",
    "When data can take on any range of values, it makes it difficult to interpret. Therefore, data scientists will convert the data into a standard format to make it easier to understand. The standard format refers to data that has 0 mean and unit variance (i.e. standard deviation = 1), and the process of converting data into this format is called data standardization.\n",
    "\n",
    "Data standardization is a relatively simple process. For each data value, x, we subtract the overall mean of the data, μ, then divide by the overall standard deviation, σ. The new value, z, represents the standardized data value. Thus, the formula for data standardization is:\n",
    "\n",
    "# &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; z = (x-µ)/σ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. NumPy and scikit-learn\n",
    "For most scikit-learn functions, the input data comes in the form of a NumPy array.\n",
    "\n",
    "Note: The array’s rows represent individual data observations, while each column represents a particular feature of the data, i.e. the same format as a spreadsheet data table.\n",
    "\n",
    "The scikit-learn data preprocessing module is called sklearn.preprocessing. One of the functions in this module, scale, applies data standardization to a given axis of a NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2140.    10.8  804. ]\n",
      "array([[-1.81319366e-01, -1.17108009e+00, -1.52646555e-01],\n",
      "       [ 1.63187429e+00,  2.92770022e-01,  1.75543539e+00],\n",
      "       [ 0.00000000e+00,  2.60032015e-15,  0.00000000e+00],\n",
      "       [-1.54121461e+00, -1.17108009e+00, -1.67911211e+00],\n",
      "       [-6.34617779e-01,  1.75662013e+00, -1.52646555e-01],\n",
      "       [ 7.25277462e-01,  2.92770022e-01,  2.28969833e-01]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# just for checking something regarding it's stadardization (what is it actually, what is standarization do)\n",
    "pizza_data = np.array([[2100, 10, 800],\n",
    "                       [2500, 11, 850],\n",
    "                       [2140, 10.8, 804],\n",
    "                       [1800, 10, 760],\n",
    "                       [2000, 12, 800],\n",
    "                       [2300, 11, 810]])\n",
    "mean = np.mean(pizza_data[:,:1]) # it only gives the mean of column 1st\n",
    "mean = np.mean(pizza_data[:], axis = 0) # it gives the mean of all columns\n",
    "print(mean) \n",
    "from sklearn.preprocessing import scale\n",
    "# Standardizing each column of pizza_data\n",
    "col_standardized = scale(pizza_data)\n",
    "print('{}\\n'.format(repr(col_standardized)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standarization means that the mean of the values is consider as 0 and according to that a number which is greater than mean is positive and the number which is less than mean is negative \n",
    "And also in standarization the variance(standard deviation) is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2140.    10.8  804. ]\n",
      "array([[2100,   10,  800],\n",
      "       [2500,   11,  850],\n",
      "       [1800,   10,  760],\n",
      "       [2000,   12,  800],\n",
      "       [2300,   11,  810]])\n",
      "array([[-0.16552118, -1.06904497, -0.1393466 ],\n",
      "       [ 1.4896906 ,  0.26726124,  1.60248593],\n",
      "       [-1.40693001, -1.06904497, -1.53281263],\n",
      "       [-0.57932412,  1.60356745, -0.1393466 ],\n",
      "       [ 0.66208471,  0.26726124,  0.2090199 ]])\n",
      "\n",
      "array([ 0., -0.,  0.])\n",
      "\n",
      "array([1., 1., 1.])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pizza_data = np.array([[2100,   10,  800],\n",
    "                       [2500,   11,  850],\n",
    "                       [1800,   10,  760],\n",
    "                       [2000,   12,  800],\n",
    "                       [2300,   11,  810]])\n",
    "mean = np.mean(pizza_data[:],axis = 0) # it gives the \n",
    "print(mean) \n",
    "print(repr(pizza_data))\n",
    "from sklearn.preprocessing import scale\n",
    "# Standardizing each column of pizza_data\n",
    "col_standardized = scale(pizza_data)\n",
    "print('{}\\n'.format(repr(col_standardized)))\n",
    "\n",
    "# Column means (rounded to nearest thousandth)\n",
    "col_means = col_standardized.mean(axis=0).round(decimals=3)\n",
    "print('{}\\n'.format(repr(col_means)))\n",
    "\n",
    "# Column standard deviations\n",
    "col_stds = col_standardized.std(axis=0)\n",
    "print('{}\\n'.format(repr(col_stds)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We normally standardize the data independently across each feature of the data array. This way, we can see how many standard deviations a particular observation’s feature value is from the mean.\n",
    "\n",
    "For example, the second data observation in pizza_data has a net weight of 1.6 standard deviations above the mean pizza weight in the dataset.\n",
    "\n",
    "If for some reason we need to standardize the data across rows, rather than columns, we can set the axis keyword argument in the scale function to 1. This may be the case when analyzing data within observations, rather than within a feature. An example of this would be analyzing a particular student’s test scores in terms of standard deviations from that student’s average test score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
