{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (150, 4)\n",
      "\n",
      "Labels shape: (150,)\n",
      "\n",
      "Coefficients: array([ 0.        , -0.        ,  0.40811896,  0.        ])\n",
      "\n",
      "Intercept: -0.5337110569441172\n",
      "\n",
      "R2: 0.895821120274704\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from IPython import get_ipython\n",
    "import import_ipynb\n",
    "get_ipython().run_line_magic('run','03_LASSO_Regression.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Grid-search cross-validation\n",
    "If our application requires us to absolutely obtain the best hyperparameters of a model, and if the dataset is small enough, we can apply an exhaustive grid search for tuning hyperparameters. For the grid search cross-validation, we specify possible values for each hyperparameter, and then the search will go through each possible combination of the hyperparameters and return the model with the best combination.\n",
    "\n",
    "We implement grid search cross-validation with the GridSearchCV object (part of the model_selection module)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha_1': 0.1, 'alpha_2': 0.3}\n"
     ]
    }
   ],
   "source": [
    "train_data = data[:100] # 100th is excluded only from 0 to 99\n",
    "test_data = data[100:] # 100th is included from 100 to 149\n",
    "train_labels = labels[:100]\n",
    "test_labels = labels[100:]\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "reg = linear_model.BayesianRidge()\n",
    "params = {\n",
    "  'alpha_1':[0.1,0.2,0.3],\n",
    "  'alpha_2':[0.1,0.2,0.3]\n",
    "}\n",
    "reg_cv = GridSearchCV(reg, params, cv=5)\n",
    "# predefined train and test sets\n",
    "reg_cv.fit(train_data, train_labels)\n",
    "print(reg_cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code example above, we searched through each possible pair of α1 and α2 values based on the two lists in the params dictionary. The search resulted in an α1 value of 0.3 and an α2 value of 0.1. For each of the models we've covered, you can take a look at their respective scikit-learn code documentation pages to determine the model's hyperparameters that can be used as the params argument for GridSearchCV.\n",
    "\n",
    "The cv keyword argument represents the number of folds used in the K-Fold cross-validation for grid search.\n",
    "\n",
    "Since exhaustive grid search performs cross-validation on each possible hyperparameter value combination, it can be incredibly slow for larger datasets. It should only be used if the dataset is reasonably small and it is important to choose the best hyperparameter combination."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
